{
  "author": "['Blair Hanley Frank']",
  "descendant": false,
  "description": "The future of Android will be a lot smarter, thanks to new programming tools that Google unveiled on Wednesday.",
  "downloadDate": "2017-05-18 12:47:25",
  "filename": "article_3197412_mobile_heres-how-google-is-preparing-android-for-the-ai-laden-future_1495111645.html",
  "image": "http://images.techhive.com/images/article/2017/02/p1200739-100709409-large.3x2.jpg",
  "language": "en",
  "localpath": "/Users/felix/news-please//data/2017/05/18/pcworld.com/article_3197412_mobile_heres-how-google-is-preparing-android-for-the-ai-laden-future_1495111645.html",
  "modifiedDate": "2017-05-18 12:47:25",
  "pageTitle": "Here's how Google is preparing Android for the AI-laden future | PCWorld",
  "publish_date": "2017-05-18 00:00:00",
  "rss_title": "NULL",
  "sourceDomain": "pcworld.com",
  "text": "The future of Android will be a lot smarter, thanks to new programming tools that Google unveiled on Wednesday. The company announced TensorFlow Lite, a version of its machine learning framework that\u2019s designed to run on smartphones and other mobile devices, during the keynote address at its Google I/O developer conference.\n\u201cTensorFlow Lite will leverage a new neural network API to tap into silicon-specific accelerators, and over time we expect to see [digital signal processing chips] specifically designed for neural network inference and training,\u201d said Dave Burke, Google\u2019s vice president of engineering for Android. \u201cWe think these new capabilities will help power a next generation of on-device speech processing, visual search, augmented reality, and more.\u201d\nThe Lite framework will be made a part of the open source TensorFlow project soon, and the neural network API will come to the next major release of Android later this year.\nThe framework has serious implications for what Google sees as the future of mobile hardware. AI-focused chips could make it possible for smartphones to handle more advanced machine learning computations without consuming as much power. With more applications using machine learning to provide intelligent experiences, making that sort of work more easily possible on device is key.\nRight now, building advanced machine learning into applications\u2014especially when it comes to training models\u2014requires an amount of computational power that typically requires beefy hardware, a lot of time and a lot of power. That\u2019s not really practical for consumer smartphone applications, which means they often offload that processing to massive datacenter by sending images, text and other data in need of processing over the internet.\nProcessing that data in the cloud comes with several downsides, according to Patrick Moorhead, principal analyst at Moor Insights and Strategy: Users must be willing to transfer their data to a company\u2019s servers, and they have to be in an environment with rich enough connectivity to make sure the operation is low-latency.\nThere\u2019s already one mobile processor with a machine learning-specific DSP on the market today. The Qualcomm Snapdragon 835 system-on-a-chip sports the Hexagon DSP that supports TensorFlow. DSPs are also used for providing functionality like recognizing the \u201cOK, Google\u201d wake phrase for the Google Assistant, according to Moorhead.\nUsers should expect to see more machine learning acceleration chips in the future, Moorhead said. \u201cEver since Moore\u2019s Law slowed down, it\u2019s been a heterogeneous computing model,\u201d he said. \u201cWe\u2019re using different kinds of processors to do different types of things, whether it\u2019s a DSP, whether it\u2019s a [field-programmable gate array], or whether it\u2019s a CPU. It\u2019s almost like we\u2019re using the right golf club for the right hole.\u201d\nGoogle is already investing in ML-specific hardware with its line of Tensor Processing Unit chips, which are designed to accelerate both the training of new machine learning algorithms as well as data processing using existing models. On Wednesday, the company announced the second version of that hardware, which is designed to accelerate machine learning training and inference.\nThe company is also not the only one with a smartphone-focused machine learning framework. Facebook showed off a mobile-oriented ML framework called Caffe2Go last year, which is used to power applications like the company\u2019s live style transfer feature.",
  "title": "Here's how Google is preparing Android for the AI-laden future",
  "url": "http://www.pcworld.com/article/3197412/mobile/heres-how-google-is-preparing-android-for-the-ai-laden-future.html"
}